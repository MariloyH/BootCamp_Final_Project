{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d69e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b843b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e2055",
   "metadata": {},
   "source": [
    "# Importing Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a756d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Resources/All_Restaurants.csv\"\n",
    "newrestaurants_df = pd.read_csv(file_path)\n",
    "newrestaurants_df[\"ID\"].count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d270032",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only stars and text\n",
    "#yelp_data = newrestaurants_df[['ID', 'user_id', 'stars', 'text']]\n",
    "yelp_data = newrestaurants_df[['ID', 'Rating', 'Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop = []\n",
    "for word in stopwords.words('english'):\n",
    "    s = [char for char in word if char not in string.punctuation]\n",
    "    stop.append(''.join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f25c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return \" \".join([word for word in nopunc.split() if word.lower() not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147afb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_data['Review'] = yelp_data['Review'].apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train test for testing the model later\n",
    "vld_size=0.15\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(yelp_data['Review'], df['ID'], test_size = vld_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee900c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_df = yelp_data[['user_id','text']]\n",
    "business_df = yelp_data[['business_id', 'text']]\n",
    "userid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f73bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_df[userid_df['user_id']=='ZwVz20be-hOZnyAbevyMyQ']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f97ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cbc6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_df = userid_df.groupby('user_id').agg({'text': ' '.join})\n",
    "business_df = business_df.groupby('business_id').agg({'text': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbb0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_df.loc['ZwVz20be-hOZnyAbevyMyQ']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b3f0e3",
   "metadata": {},
   "source": [
    "# User Tfidf Vectorizer with 5000 Features (represent 88% of all words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c067272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a814c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#userid vectorizer\n",
    "userid_vectorizer = TfidfVectorizer(tokenizer = WordPunctTokenizer().tokenize, max_features=5000)\n",
    "userid_vectors = userid_vectorizer.fit_transform(userid_df['text'])\n",
    "userid_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c95747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Business id vectorizer\n",
    "businessid_vectorizer = TfidfVectorizer(tokenizer = WordPunctTokenizer().tokenize, max_features=5000)\n",
    "businessid_vectors = businessid_vectorizer.fit_transform(business_df['text'])\n",
    "businessid_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0ba99",
   "metadata": {},
   "source": [
    "#Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088dbabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_rating_matrix = pd.pivot_table(yelp_data, values='stars', index=['user_id'], columns=['business_id'])\n",
    "userid_rating_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f4aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "userid_rating_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = pd.DataFrame(userid_vectors.toarray(), index=userid_df.index, columns=userid_vectorizer.get_feature_names())\n",
    "Q = pd.DataFrame(businessid_vectors.toarray(), index=business_df.index, columns=businessid_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d35cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(R, P, Q, steps=25, gamma=0.001,lamda=0.02):\n",
    "    for step in range(steps):\n",
    "        for i in R.index:\n",
    "            for j in R.columns:\n",
    "                if R.loc[i,j]>0:\n",
    "                    eij=R.loc[i,j]-np.dot(P.loc[i],Q.loc[j])\n",
    "                    P.loc[i]=P.loc[i]+gamma*(eij*Q.loc[j]-lamda*P.loc[i])\n",
    "                    Q.loc[j]=Q.loc[j]+gamma*(eij*P.loc[i]-lamda*Q.loc[j])\n",
    "        e=0\n",
    "        for i in R.index:\n",
    "            for j in R.columns:\n",
    "                if R.loc[i,j]>0:\n",
    "                    e= e + pow(R.loc[i,j]-np.dot(P.loc[i],Q.loc[j]),2)+lamda*(pow(np.linalg.norm(P.loc[i]),2)+pow(np.linalg.norm(Q.loc[j]),2))\n",
    "        if e<0.001:\n",
    "            break\n",
    "        \n",
    "    return P,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "P, Q = matrix_factorization(userid_rating_matrix, P, Q, steps=25, gamma=0.001,lamda=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.iloc[0].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd8584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store P, Q and vectorizer in pickle file\n",
    "import pickle\n",
    "output = open('yelp_recommendation_model_8.pkl', 'wb')\n",
    "pickle.dump(P,output)\n",
    "pickle.dump(Q,output)\n",
    "pickle.dump(userid_vectorizer,output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction for input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb6ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"i want to have dinner with beautiful views\"\n",
    "test_df= pd.DataFrame([words], columns=['text'])\n",
    "test_df['text'] = test_df['text'].apply(text_process)\n",
    "test_vectors = userid_vectorizer.transform(test_df['text'])\n",
    "test_v_df = pd.DataFrame(test_vectors.toarray(), index=test_df.index, columns=userid_vectorizer.get_feature_names())\n",
    "\n",
    "predictItemRating=pd.DataFrame(np.dot(test_v_df.loc[0],Q.T),index=Q.index,columns=['Rating'])\n",
    "topRecommendations=pd.DataFrame.sort_values(predictItemRating,['Rating'],ascending=[0])[:7]\n",
    "\n",
    "for i in topRecommendations.index:\n",
    "    print(df_business[df_business['business_id']==i]['name'].iloc[0])\n",
    "    print(df_business[df_business['business_id']==i]['categories'].iloc[0])\n",
    "    print(str(df_business[df_business['business_id']==i]['stars'].iloc[0])+ ' '+str(df_business[df_business['business_id']==i]['review_count'].iloc[0]))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
